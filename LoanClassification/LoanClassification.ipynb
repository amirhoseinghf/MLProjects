{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Loading The Dataset"
      ],
      "metadata": {
        "id": "F3QkaL_xwJdB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RT8xO-IS-qyR",
        "outputId": "5ee05e01-a64c-41ea-c63b-c072c1f8f085"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (45000, 14)\n",
            "\n",
            "First 5 rows:\n",
            "   person_age person_gender person_education  person_income  person_emp_exp  \\\n",
            "0        22.0        female           Master        71948.0               0   \n",
            "1        21.0        female      High School        12282.0               0   \n",
            "2        25.0        female      High School        12438.0               3   \n",
            "3        23.0        female         Bachelor        79753.0               0   \n",
            "4        24.0          male           Master        66135.0               1   \n",
            "\n",
            "  person_home_ownership  loan_amnt loan_intent  loan_int_rate  \\\n",
            "0                  RENT    35000.0    PERSONAL          16.02   \n",
            "1                   OWN     1000.0   EDUCATION          11.14   \n",
            "2              MORTGAGE     5500.0     MEDICAL          12.87   \n",
            "3                  RENT    35000.0     MEDICAL          15.23   \n",
            "4                  RENT    35000.0     MEDICAL          14.27   \n",
            "\n",
            "   loan_percent_income  cb_person_cred_hist_length  credit_score  \\\n",
            "0                 0.49                         3.0           561   \n",
            "1                 0.08                         2.0           504   \n",
            "2                 0.44                         3.0           635   \n",
            "3                 0.44                         2.0           675   \n",
            "4                 0.53                         4.0           586   \n",
            "\n",
            "  previous_loan_defaults_on_file  loan_status  \n",
            "0                             No            1  \n",
            "1                            Yes            0  \n",
            "2                             No            1  \n",
            "3                             No            1  \n",
            "4                             No            1  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('loan_data.csv')\n",
        "\n",
        "# Display basic information\n",
        "print(\"Dataset shape:\", df.shape)\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "O6HDwOexh4-y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking for Null values"
      ],
      "metadata": {
        "id": "hJ06I_7Vh9RG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Missing values per column:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsQP2KYB-1Wk",
        "outputId": "d025404a-d9ff-4fb7-f8ef-c91691891af1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values per column:\n",
            "person_age                        0\n",
            "person_gender                     0\n",
            "person_education                  0\n",
            "person_income                     0\n",
            "person_emp_exp                    0\n",
            "person_home_ownership             0\n",
            "loan_amnt                         0\n",
            "loan_intent                       0\n",
            "loan_int_rate                     0\n",
            "loan_percent_income               0\n",
            "cb_person_cred_hist_length        0\n",
            "credit_score                      0\n",
            "previous_loan_defaults_on_file    0\n",
            "loan_status                       0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems like we don't have missing values! Let's Continue"
      ],
      "metadata": {
        "id": "LuDkVy2ri3Ah"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transforming Categorical features to Numerical features"
      ],
      "metadata": {
        "id": "nKQMFGoai6xn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoding Strategy\n",
        "1. **Binary Encoding:**  \n",
        "   - `person_gender`: Convert `female` → 0, `male` → 1  \n",
        "   - `previous_loan_defaults_on_file`: Convert `No` → 0, `Yes` → 1  \n",
        "\n",
        "2. **Ordinal Encoding:**  \n",
        "   - `person_education`: Since education levels have an order, we can map them as:  \n",
        "     - `High School` → 0  \n",
        "     - `Bachelor` → 1  \n",
        "     - `Master` → 2  \n",
        "     - `PhD` → 3  \n",
        "\n",
        "3. **One-Hot Encoding:**  \n",
        "   - `person_home_ownership` (categorical with no order): Convert `RENT`, `OWN`, and `MORTGAGE` into separate binary columns  \n",
        "   - `loan_intent` (categorical with no order): Convert `PERSONAL`, `EDUCATION`, `MEDICAL`, etc., into separate binary columns  \n"
      ],
      "metadata": {
        "id": "z6_9PcSCjiXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Binary Encoding\n",
        "df[\"person_gender\"] = df[\"person_gender\"].map({\"female\": 0, \"male\": 1})\n",
        "df[\"previous_loan_defaults_on_file\"] = df[\"previous_loan_defaults_on_file\"].map({\"No\": 0, \"Yes\": 1})\n",
        "\n",
        "# Ordinal Encoding\n",
        "education_mapping = {\"High School\": 0, \"Bachelor\": 1, \"Master\": 2, \"PhD\": 3}\n",
        "df[\"person_education\"] = df[\"person_education\"].map(education_mapping)\n",
        "\n",
        "# One-Hot Encoding\n",
        "df = pd.get_dummies(df, columns=[\"person_home_ownership\", \"loan_intent\"])\n",
        "\n",
        "# Fill any NaN values with 0, then convert to int\n",
        "df = df.fillna(0).astype(int)\n",
        "\n",
        "# Display the transformed dataset\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C01ixdrYjCya",
        "outputId": "87dd7222-f910-4dc8-92a9-79b7a936f2bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   person_age  person_gender  person_education  person_income  person_emp_exp  \\\n",
            "0          22              0                 2          71948               0   \n",
            "1          21              0                 0          12282               0   \n",
            "2          25              0                 0          12438               3   \n",
            "3          23              0                 1          79753               0   \n",
            "4          24              1                 2          66135               1   \n",
            "\n",
            "   loan_amnt  loan_int_rate  loan_percent_income  cb_person_cred_hist_length  \\\n",
            "0      35000             16                    0                           3   \n",
            "1       1000             11                    0                           2   \n",
            "2       5500             12                    0                           3   \n",
            "3      35000             15                    0                           2   \n",
            "4      35000             14                    0                           4   \n",
            "\n",
            "   credit_score  ...  person_home_ownership_MORTGAGE  \\\n",
            "0           561  ...                               0   \n",
            "1           504  ...                               0   \n",
            "2           635  ...                               1   \n",
            "3           675  ...                               0   \n",
            "4           586  ...                               0   \n",
            "\n",
            "   person_home_ownership_OTHER  person_home_ownership_OWN  \\\n",
            "0                            0                          0   \n",
            "1                            0                          1   \n",
            "2                            0                          0   \n",
            "3                            0                          0   \n",
            "4                            0                          0   \n",
            "\n",
            "   person_home_ownership_RENT  loan_intent_DEBTCONSOLIDATION  \\\n",
            "0                           1                              0   \n",
            "1                           0                              0   \n",
            "2                           0                              0   \n",
            "3                           1                              0   \n",
            "4                           1                              0   \n",
            "\n",
            "   loan_intent_EDUCATION  loan_intent_HOMEIMPROVEMENT  loan_intent_MEDICAL  \\\n",
            "0                      0                            0                    0   \n",
            "1                      1                            0                    0   \n",
            "2                      0                            0                    1   \n",
            "3                      0                            0                    1   \n",
            "4                      0                            0                    1   \n",
            "\n",
            "   loan_intent_PERSONAL  loan_intent_VENTURE  \n",
            "0                     1                    0  \n",
            "1                     0                    0  \n",
            "2                     0                    0  \n",
            "3                     0                    0  \n",
            "4                     0                    0  \n",
            "\n",
            "[5 rows x 22 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalization And Standardazation"
      ],
      "metadata": {
        "id": "AAV6Z19gl_wZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For a Decision Tree, neither standardization nor normalization is required because:  \n",
        "\n",
        "✅ **Decision Trees are not affected by feature scaling.** They split data based on feature values, not distances.  \n",
        "✅ **They handle different feature scales naturally.** Unlike SVM or k-NN, decision trees don’t rely on distance-based calculations.  \n"
      ],
      "metadata": {
        "id": "CAyQtf13mJF2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OMw43dp4maMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0X0p0hCSpTCN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Tree Implementation"
      ],
      "metadata": {
        "id": "jWp5PxCrpVbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "class DecisionTree:\n",
        "    def __init__(self, criterion='entropy', max_depth=None, min_samples_split=2):\n",
        "        self.criterion = criterion\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.tree = None\n",
        "\n",
        "    def calculate_entropy(self, y):\n",
        "        counts = np.bincount(y)\n",
        "        probabilities = counts / len(y)\n",
        "        entropy = -np.sum([p * np.log2(p) for p in probabilities if p > 0])\n",
        "        return entropy\n",
        "\n",
        "    def calculate_gini(self, y):\n",
        "        counts = np.bincount(y)\n",
        "        probabilities = counts / len(y)\n",
        "        gini = 1 - np.sum([p**2 for p in probabilities])\n",
        "        return gini\n",
        "\n",
        "    def calculate_impurity(self, y, criterion):\n",
        "        if criterion == 'entropy':\n",
        "            return self.calculate_entropy(y)\n",
        "        elif criterion == 'gini':\n",
        "            return self.calculate_gini(y)\n",
        "        else:\n",
        "            raise ValueError(\"Invalid criterion\")\n",
        "\n",
        "    def information_gain(self, X, y, feature, criterion='entropy'):\n",
        "        X_feature = X[:, feature]\n",
        "        sorted_unique = np.unique(X_feature)\n",
        "        if len(sorted_unique) <= 1:\n",
        "            return None, 0\n",
        "\n",
        "        thresholds = (sorted_unique[:-1] + sorted_unique[1:]) / 2\n",
        "        max_gain = -np.inf\n",
        "        best_threshold = None\n",
        "\n",
        "        parent_impurity = self.calculate_impurity(y, criterion)\n",
        "        n_samples = len(y)\n",
        "\n",
        "        for threshold in thresholds:\n",
        "            left_indices = X_feature <= threshold\n",
        "            right_indices = X_feature > threshold\n",
        "            y_left = y[left_indices]\n",
        "            y_right = y[right_indices]\n",
        "\n",
        "            if len(y_left) == 0 or len(y_right) == 0:\n",
        "                continue\n",
        "\n",
        "            left_impurity = self.calculate_impurity(y_left, criterion)\n",
        "            right_impurity = self.calculate_impurity(y_right, criterion)\n",
        "            child_impurity = (len(y_left) * left_impurity + len(y_right) * right_impurity) / n_samples\n",
        "            gain = parent_impurity - child_impurity\n",
        "\n",
        "            if gain > max_gain:\n",
        "                max_gain = gain\n",
        "                best_threshold = threshold\n",
        "\n",
        "        if best_threshold is None:\n",
        "            return None, 0\n",
        "        return best_threshold, max_gain\n",
        "\n",
        "    def best_split(self, X, y, criterion='entropy'):\n",
        "        best_feature = None\n",
        "        best_threshold = None\n",
        "        best_gain = -np.inf\n",
        "\n",
        "        for feature in range(X.shape[1]):\n",
        "            threshold, gain = self.information_gain(X, y, feature, criterion)\n",
        "            if gain > best_gain:\n",
        "                best_gain = gain\n",
        "                best_feature = feature\n",
        "                best_threshold = threshold\n",
        "\n",
        "        return best_feature, best_threshold\n",
        "\n",
        "    def is_pure(self, y):\n",
        "        return len(set(y)) == 1\n",
        "\n",
        "    def create_leaf_node(self, y):\n",
        "        counts = Counter(y)\n",
        "        majority_class = max(counts, key=counts.get)\n",
        "        return {'class': majority_class}\n",
        "\n",
        "    def build_tree(self, X, y, max_depth, min_samples_split, depth=0):\n",
        "        if (self.max_depth is not None and depth >= max_depth) or (len(y) < min_samples_split) or self.is_pure(y):\n",
        "            return self.create_leaf_node(y)\n",
        "\n",
        "        best_feature, best_threshold = self.best_split(X, y, self.criterion)\n",
        "        if best_feature is None:\n",
        "            return self.create_leaf_node(y)\n",
        "\n",
        "        left_indices = X[:, best_feature] <= best_threshold\n",
        "        right_indices = X[:, best_feature] > best_threshold\n",
        "\n",
        "        X_left, y_left = X[left_indices], y[left_indices]\n",
        "        X_right, y_right = X[right_indices], y[right_indices]\n",
        "\n",
        "        if len(y_left) == 0 or len(y_right) == 0:\n",
        "            return self.create_leaf_node(y)\n",
        "\n",
        "        left_subtree = self.build_tree(X_left, y_left, max_depth, min_samples_split, depth + 1)\n",
        "        right_subtree = self.build_tree(X_right, y_right, max_depth, min_samples_split, depth + 1)\n",
        "\n",
        "        return {\n",
        "            'feature': best_feature,\n",
        "            'threshold': best_threshold,\n",
        "            'left': left_subtree,\n",
        "            'right': right_subtree\n",
        "        }\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.tree = self.build_tree(X, y, self.max_depth, self.min_samples_split)\n",
        "\n",
        "    def _predict_tree(self, x, node):\n",
        "        if 'class' in node:\n",
        "            return node['class']\n",
        "        feature_value = x[node['feature']]\n",
        "        if feature_value <= node['threshold']:\n",
        "            return self._predict_tree(x, node['left'])\n",
        "        else:\n",
        "            return self._predict_tree(x, node['right'])\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.array([self._predict_tree(x, self.tree) for x in X])\n",
        "\n",
        "    def evaluate(self, y_true, y_pred):\n",
        "        classes = np.unique(y_true)\n",
        "        n_classes = len(classes)\n",
        "        cm = np.zeros((n_classes, n_classes), dtype=int)\n",
        "\n",
        "        for i in range(len(y_true)):\n",
        "            true_idx = np.where(classes == y_true[i])[0][0]\n",
        "            pred_idx = np.where(classes == y_pred[i])[0][0]\n",
        "            cm[true_idx, pred_idx] += 1\n",
        "\n",
        "        accuracy = np.trace(cm) / np.sum(cm)\n",
        "\n",
        "        recalls = []\n",
        "        precisions = []\n",
        "        f1_scores = []\n",
        "\n",
        "        for i in range(n_classes):\n",
        "            tp = cm[i, i]\n",
        "            fp = np.sum(cm[:, i]) - tp\n",
        "            fn = np.sum(cm[i, :]) - tp\n",
        "\n",
        "            recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "            precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
        "            f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "\n",
        "            recalls.append(recall)\n",
        "            precisions.append(precision)\n",
        "            f1_scores.append(f1)\n",
        "\n",
        "        macro_recall = np.mean(recalls)\n",
        "        macro_precision = np.mean(precisions)\n",
        "        macro_f1 = np.mean(f1_scores)\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'recall': macro_recall,\n",
        "            'precision': macro_precision,\n",
        "            'f1_score': macro_f1\n",
        "        }"
      ],
      "metadata": {
        "id": "ux8B9wA4pp5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training The Model"
      ],
      "metadata": {
        "id": "qn5sY4aBueHA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting Data"
      ],
      "metadata": {
        "id": "XIbqWparunaf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns=['loan_status'])  # Features\n",
        "y = df['loan_status']  # Target variable\n",
        "\n",
        "# Split data into 80% train and 20% test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "6bU8nBwAupjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training The Model"
      ],
      "metadata": {
        "id": "NDUjKs-vu0DE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and train the DecisionTree model\n",
        "tree = DecisionTree(criterion='entropy', max_depth=5, min_samples_split=2)\n",
        "tree.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "MVSRhfDrsSY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making Predictions And Evaluating The Model"
      ],
      "metadata": {
        "id": "1xO2lzpWvGMl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "y_pred = tree.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "metrics = tree.evaluate(y_test, y_pred)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"Model Evaluation Metrics:\")\n",
        "for metric, value in metrics.items():\n",
        "    print(f\"{metric}: {value:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHGBQWtiu3cm",
        "outputId": "9e28ae2a-4cae-431f-ce50-4d7390191860"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Evaluation Metrics:\n",
            "accuracy: 0.8972\n",
            "recall: 0.8309\n",
            "precision: 0.8628\n",
            "f1_score: 0.8452\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zmkBVesuvKZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using DecisionTreeClassifier"
      ],
      "metadata": {
        "id": "dBhGv3s1vlzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Initialize the DecisionTreeClassifier\n",
        "sklearn_tree = DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_split=2, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "sklearn_tree.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_sklearn = sklearn_tree.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred_sklearn)\n",
        "precision = precision_score(y_test, y_pred_sklearn)\n",
        "recall = recall_score(y_test, y_pred_sklearn)\n",
        "f1 = f1_score(y_test, y_pred_sklearn)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"Sklearn DecisionTreeClassifier Evaluation Metrics:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XR5Uug2Zvsg9",
        "outputId": "7a8d34a4-76eb-4a35-bbc6-ef4fa64dc5de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sklearn DecisionTreeClassifier Evaluation Metrics:\n",
            "Accuracy: 0.8972\n",
            "Precision: 0.8060\n",
            "Recall: 0.7109\n",
            "F1 Score: 0.7555\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks Like my Precision, Recall, and F1 Score is better than Sklearn DecisionTreeClassifier!"
      ],
      "metadata": {
        "id": "TwlDq1g9v0PD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LgK2g9Abvugq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}